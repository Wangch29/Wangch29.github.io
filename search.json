[{"title":"Bustub project 3 优化","url":"/2024/12/08/Bustub/project3-leaderboard/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# 前言\n\n这是一个关于我自己的cmu15-445 project 3 leaderboard部分的攻略，不会涉及其前面基础实现部分。最终效果三个部分平均用时2000以内，进了排行榜前十。\n\n![](https://i-blog.csdnimg.cn/direct/059ce9aa4865460797af7c48176abc08.png#pic_center)\n引自[joey-wang](https://www.cnblogs.com/joey-wang/p/17351258.html)\n\n# Query 1: TopNPerGroupPlan\n\n根据例子：\n\n```sql\nCREATE TABLE t1(x INT, y INT, z INT);\nSELECT x, y FROM (\n  SELECT x, y, rank() OVER (partition by x order by y) as rank\n  FROM t1\n) WHERE rank <= 3;\n```\n\n首先可以通过Bustub shell 里的 explain 得其目前的 plan tree，来分析一下执行过程:\n\n```\n=== OPTIMIZER ===\nProjection { exprs=[\"#0.0\", \"#0.1\"] }\n  Filter { predicate=(#0.2<=3) }\n    WindowFunc {\n      columns=#0.0, #0.1, placeholder, ,\n      window_functions={\n        2=>{ function_arg=1, type=rank, partition_by=[\"#0.0\"], order_by=[(\"Default\", \"#0.1\")] }\n      }\n    }\n      SeqScan { table=t1 }\n```\n\n可看出其有四个plan node，执行顺序如下：\n```\nSeqscan -> WindowFunc -> Filter -> Projection\n```\n\n当满足Projection <-Filter <- WindowFunc顺序，且projection将windowFunc产生的rank列清除时，它们三个node可以合并成一个TopNPerGroupPlan，扫描后直接返回每个group排名前N的tuple，即：\n```\nSeqscan -> TopNPerGroupPlan\n```\n即可在optimizer.h新增一个优化pattern：\n\n```cpp\nauto OptimizeProjectionFilterWindowAsTopGroupN(const AbstractPlanNodeRef &plan) -> AbstractPlanNodeRef;\n```\n你会发现原本bustub自带的优化method实现都是在一个新的.cpp文件中，为了统一格式你自然会想到新创建一个OptimizeProjectionFilterWindowAsTopGroupN.cpp来实现该函数，再加入cmakelists里。但事与愿违，由于gradescope的限制，如果你想线上测试，就不能自己新建文件，而要在项目指定optimizer_custom_rules.cpp里实现。这点会让optimizer_custom_rules.cpp往后变的很臃肿，希望课程以后能改进这一点吧。。。\n\n主要思路是利用一个可以保留多个tuple 的特殊priority queue来为每个组保留top N个tuple。注意如果有相等的tuple，需要同时保留，例子可见p3.leaderboard_test_q1_window。还要用一个hashmap 来分组。过程就是：先拿到一个tuple，然后获得其group值，利用group值做key在一个**hashmap**中找到其所在group对应的priority queue，然后插入。这时候只需要**自定义一下这个priority queue，让其自动保存前n个tuple就可以了。**\n\n对于OptimizeProjectionFilterWindowAsTopGroupN，则是依次查看三层nodeplan，如果满足“***Projection <-Filter <- WindowFunc顺序，且projection将windowFunc产生的rank列清除时***”，即可优化成TopNPerGroup node。可以利用shell中的explain (o)语句来查看优化是否成功。\n\n具体实现如下：\n```cpp\nauto Optimizer::OptimizeProjectionFilterWindowAsTopGroupN(const AbstractPlanNodeRef &plan) -> AbstractPlanNodeRef {\n  std::vector<AbstractPlanNodeRef> optimized_children{};\n  for (const auto &child : plan->children_) {\n    optimized_children.emplace_back(OptimizeProjectionFilterWindowAsTopGroupN(child));\n  }\n  auto optimized_plan = plan->CloneWithChildren(std::move(optimized_children));\n\n  // First node is Projection.\n  if (optimized_plan->GetType() == PlanType::Projection) {\n    const auto &projection_plan = dynamic_cast<const ProjectionPlanNode &>(*optimized_plan);\n    auto &first_child = projection_plan.GetChildren().at(0);\n    // Second node is filter.\n    if (first_child->GetType() == PlanType::Filter) {\n      const auto &filter_child = dynamic_cast<const FilterPlanNode &>(*first_child);\n      // auto filter_logic_expr = dynamic_cast<const LogicExpression&>(filter_child.predicate_);\n      auto &second_child = filter_child.GetChildren().at(0);\n      // Third node is window.\n      if (second_child->GetType() == PlanType::Window) {\n        const auto &window_child = dynamic_cast<const WindowFunctionPlanNode &>(*second_child);\n        // Try to find Rank's col index.\n        int rank_idx = -1;\n        std::string rank_name;\n        for (size_t col = 0; col < window_child.columns_.size(); ++col) {\n          if (window_child.window_functions_.find(rank_idx) != window_child.window_functions_.end()) {\n            // Is a window function\n            if (window_child.window_functions_.at(rank_idx).type_ == WindowFunctionType::Rank) {\n              rank_idx = col;\n              rank_name = window_child.OutputSchema().GetColumn(rank_idx).GetName();\n              goto OptimizeProjectionFilterWindowAsTopGroupN_END;;\n            }\n          }\n        }\n        // If we find Rank, we can continue to check if it stays after projection.\n        if (rank_idx != -1) {\n          const auto &projection_schema = projection_plan.OutputSchema();\n          for (auto &column : projection_schema.GetColumns()) {\n            if (column.GetName() == rank_name) {  // Find the rank line\n              goto OptimizeProjectionFilterWindowAsTopGroupN_END;\n            }\n          }\n        }\n        // Projection removed RANK, we can optimize it to TopGroupN node.\n        // Find group_bys\n        const std::vector<AbstractExpressionRef> &group_by =\n            window_child.window_functions_.begin()->second.partition_by_;\n        // Find order by\n        const std::vector<std::pair<OrderByType, AbstractExpressionRef>> &order_by =\n            window_child.window_functions_.begin()->second.order_by_;\n        // Find top n;\n        auto value_expr = dynamic_cast<const ConstantValueExpression &>(*filter_child.predicate_->GetChildAt(1));\n        // auto value_expr = dynamic_cast<const ConstantValueExpression &>(*maybe_value_expr);\n        int n = value_expr.val_.CastAs(TypeId::INTEGER).GetAs<int>();\n        return std::make_shared<TopNPerGroupPlanNode>(projection_plan.output_schema_, window_child.children_.at(0),\n                                                      group_by, order_by, n);\n      }\n    }\n  }\n\nOptimizeProjectionFilterWindowAsTopGroupN_END:\n  return optimized_plan;\n}\n```\n在topn_per_group_executor.cpp：\n```cpp\nvoid TopNPerGroupExecutor::Init() {\n  child_executor_->Init();\n  partition_top_n_.clear();\n  \n  size_t top_n = plan_->n_;\n  auto group_by = plan_->GetGroupBy();\n  CompareTuple comparator(&plan_->GetOrderBy(), &child_executor_->GetOutputSchema());\n\n  // Use a priority queue to store the top N tuples for each group.\n  Tuple tuple;\n  RID rid;\n  while (child_executor_->Next(&tuple, &rid)) {   // nlogn\n    AggregateKey group_by_key = ConstructGroupByTuple(tuple, group_by);\n    auto it = partition_top_n_.find(group_by_key);\n    if (partition_top_n_.find(group_by_key) == partition_top_n_.end()) {\n      it = partition_top_n_.emplace(group_by_key, TopNTuplePriorityQueue(top_n, comparator)).first;\n    }\n    it->second.Push(tuple);\n  }\n\n  iter_ = partition_top_n_.begin();\n}\n\nauto TopNPerGroupExecutor::Next(Tuple *tuple, RID *rid) -> bool {\n  if (iter_ != partition_top_n_.end()) {\n    if (iter_->second.Empty()) {\n      // Move to the next pq, and erase current pq.\n      iter_ = partition_top_n_.erase(iter_);\n      return Next(tuple, rid);\n    }\n    *tuple = iter_->second.Pop();\n    *rid = tuple->GetRid();\n    return true;\n  }\n  return false;\n}\n```\n自定义版priority queue：\n```cpp\n  class TopNTuplePriorityQueue {\n   public:\n    explicit TopNTuplePriorityQueue(std::size_t n, CompareTuple comparator)\n        : n_(n), pq_(comparator), freq_map_(comparator) {}\n\n    void Push(const Tuple &tuple) {\n      pq_.push(tuple);\n      freq_map_[tuple] += 1;\n      MaintainSize();\n    }\n\n    auto Pop() -> Tuple {\n      if (pq_.empty()) [[unlikely]] {\n        throw std::runtime_error(\"TopNTuplePriorityQueue is empty\");\n      }\n      Tuple top_tuple = pq_.top();\n      pq_.pop();\n      return top_tuple;\n    }\n\n    auto Empty() -> bool { return pq_.empty(); }\n\n   private:\n    std::size_t n_;\n    std::priority_queue<Tuple, std::vector<Tuple>, CompareTuple> pq_;\n    std::map<Tuple, size_t, CompareTuple> freq_map_;\n\n    void MaintainSize() {\n      while (pq_.size() > n_) {\n        // If removing top elements will lead to underflow, break;\n        if (pq_.size() - freq_map_[pq_.top()] < n_) {\n          break;\n        }\n        // Remove top tuples.\n        while (freq_map_[pq_.top()] > 1) {\n          freq_map_[pq_.top()] -= 1;\n          pq_.pop();\n        }\n        freq_map_.erase(pq_.top());\n        pq_.pop();\n      }\n    }\n  };\n```\n\n在top_n_per_group.h中的TupleComparator和其他一些东西就留给读者思考，不写出了，具体思路我已经在上面讲过了。而这个玩意的输出不需要按照一定顺序比如升序，只需要获得的tuple对就行。\n\n至此即可通过leaderboard test q1，我的用时目前是7000多，排十多名，在做了优化的人中算是慢的了，看来还有优化空间。\n\n做个profiling看看👀：\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/bc28397020ab4437bbce3ac400b42368.png#pic_center)\n我发现TopNTuplePriorityQueue中的**MaintainSize()**函数比我想象的耗时间。MaintainSize占据了Push过半的时间，而**freq_map_[]**又占据了MaintainSize过半的时间，所以用基于红黑树的map还是不行，可以把 std::map<Tuple, size_t, CompareTuple> freq_map_ 优化成 unordered_map。\n\n```cpp\nvoid MaintainSize() {\n      while (pq_.size() > n_) {\n        // If removing top elements will lead to underflow, break;\n        uint32_t top_tuple_freq = freq_map_[pq_.top()];\n        if (pq_.size() - top_tuple_freq < n_) {\n          break;\n        }\n        // Remove top tuples.\n        freq_map_.erase(pq_.top());\n        for (size_t i = 0; i < top_tuple_freq; ++i) {\n          pq_.pop();\n        }\n      }\n    }\n\n...\n\nstd::unordered_map<Tuple, size_t, TupleHash, TupleEqual> freq_map_;\n```\n\n然后再测试，发现居然q1用时直接从7000多减少到了4000多，快了40%多，效果十分显著啊。可见profiling对优化的指导还是很有效的。\n\n优化后再做个profiling：\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/56f81ad3ada240c29acd9eecd359ed73.png#pic_center)\n可见Push()用时大幅缩短。但leaderboard上还有神人能优化到1000多，真不知怎么做到的。\n# Query 2: Too Many Joins!\n\n## 解析\n一名来自[严辉村](https://zh.wikipedia.org/wiki/%E8%8C%83%E5%B0%8F%E5%8B%A4)的村民写了如下的sql：\n\n```sql\nCREATE TABLE t4(x int, y int);\nCREATE TABLE t5(x int, y int);\nCREATE TABLE t6(x int, y int);\n\nSELECT * FROM t4, t5, t6\n  WHERE (t4.x = t5.x) AND (t5.y = t6.y) AND (t4.y >= 1000000)\n    AND (t4.y < 1500000) AND (t6.x >= 100000) AND (t6.x < 150000);\n```\n可见他其实想吧**t4、t5 join on x, t5、t6 join on y**, 但是并没有人为地分步合并，而是一股脑地把条件全放在了**where**后面。如果没有优化，就导致该query执行的时候会把t4、t5、t6做两个笛卡尔积（**Cartesian product**，即无条件的join）生产一个巨大的table，然后遍历这个巨大的table进行过滤。\n\n当然，你在前面已经实现了包括**hash join**在内的部分优化器，所以实际上根据我个人前面的实现，会先对t4、t5进行一个基于hash join的笛卡尔积，然后再和t6进行一个有条件的hash join，最后进行一个过滤（filter node）。\n\n具体经过用explain (o)可看其plan tree:\n\n```\n=== OPTIMIZER ===\nFilter { predicate=(((((#0.0=#0.2)and(#0.1>=1000000))and(#0.1<1500000))and\n(#0.4>=100000))and(#0.4<150000)) } | \n(t4.x:INTEGER, t4.y:INTEGER, t5.x:INTEGER, t5.y:INTEGER, t6.x:INTEGER, t6.y:INTEGER)\n\n  HashJoin { type=Inner, left_key=[\"#0.3\"], right_key=[\"#1.1\"] } | \n  (t4.x:INTEGER, t4.y:INTEGER, t5.x:INTEGER, t5.y:INTEGER, t6.x:INTEGER, t6.y:INTEGER)\n  \n    HashJoin { type=Inner, left_key=[], right_key=[] } | \n    (t4.x:INTEGER, t4.y:INTEGER, t5.x:INTEGER, t5.y:INTEGER)\n    \n      SeqScan { table=t4 } | (t4.x:INTEGER, t4.y:INTEGER)\n      SeqScan { table=t5 } | (t5.x:INTEGER, t5.y:INTEGER)\n    SeqScan { table=t6 } | (t6.x:INTEGER, t6.y:INTEGER)\n```\n这个根据每个人之前对**Optimizer::OptimizeNLJAsHashJoin(**)实现的不同，这里的情况也会有不同。\n\n## 关于Hash Join\n\n而OptimizeNLJAsHashJoin其实还挺繁琐的，根据我对gradescope上leaderboard的观察，有很多人对这个函数的实现其实的错误的，**只是因为gradescope上的基础测试并不全面，他们才通过了除leaderboard外其余的基础测试**。而到了leaderboard测试，就会出现bug了。\n\n所以我讲一下我的hashjoin的实现思路：大概是用一个递归遍历NLJ_plan.predicate的tree，当发现**ColumnValueExpression**且判断式为equal且其左右孩子expression均为ColumnValueExpression且GetTupleIdx()分列左右的时候，将其加入hash join并从原expression tree中删除。而遍历后剩下的expression tree则用于创建一个filter放在hash join 上方。而且在生成filter的时候要记得修改ColumnValueExpression的col_idx。\n\n举个例子：\n```sql\nSELECT * FROM t4, t5\n WHERE (t4.x = t5.x) AND (t4.x = t4.y) AND (t4.z >= t5.z) AND (t5.x = 100);\n```\n这个query会被优化成：\n```\nFilter: (t4.x = t4.y) AND (t4.z >= t5.z) AND (t5.z = 100)\n         │\n         └── HashJoin: t4.x = t5.x\n             ├── Sequential Scan: t4\n             └── Sequential Scan: t5\n```\n四个条件只有$t4.x = t5.x$能被放入hash join, 因为$t4.x = t4.y$只作用在left child， $t4.z >= t5.z$不是等式而是不等式，$t5.x = 100$只作用于right child且有一个常数项。所以这三个判断都上移到filter。\n\n而还要考虑更复杂的NLJ的条件中logic连接词为**OR**的情况，如:\n```sql\nSELECT * FROM t4, t5\n WHERE (t4.x = t5.x) OR (t4.y = t5.y);\n```\n我目前的做法是如果存在OR就直接保持NLJ，但其实可以这样优化成：\n```sql\nSELECT *\nFROM t4, t5\nWHERE t4.x = t5.x\nUNION ALL\nSELECT *\nFROM t4, t5\nWHERE t4.y = t5.y;\n```\n或者用tree表达：\n```\nUnion All\n├── HashJoin: t4.x = t5.x\n│   ├── Sequential Scan: t4\n│   └── Sequential Scan: t5\n└── HashJoin: t4.y = t5.y\n    ├── Sequential Scan: t4\n    └── Sequential Scan: t5\n```\n即将OR连接的部分拆分成两个hash join，然后再Union起来。\n\n## 优化\n\n回到正题，这个query就是故意设计一个predicate集中分布在node tree上方，主要考察的是优化器对predicate pushdown的能力。\n\n```\nFilter { predicate=(((((#0.0=#0.2)and(#0.1>=1000000))and(#0.1<1500000))and\n(#0.4>=100000))and(#0.4<150000)) } | \n(t4.x:INTEGER, t4.y:INTEGER, t5.x:INTEGER, t5.y:INTEGER, t6.x:INTEGER, t6.y:INTEGER)\n\n  HashJoin { type=Inner, left_key=[\"#0.3\"], right_key=[\"#1.1\"] } | \n  (t4.x:INTEGER, t4.y:INTEGER, t5.x:INTEGER, t5.y:INTEGER, t6.x:INTEGER, t6.y:INTEGER)\n  \n    HashJoin { type=Inner, left_key=[], right_key=[] } | \n    (t4.x:INTEGER, t4.y:INTEGER, t5.x:INTEGER, t5.y:INTEGER)\n    \n      SeqScan { table=t4 } | (t4.x:INTEGER, t4.y:INTEGER)\n      SeqScan { table=t5 } | (t5.x:INTEGER, t5.y:INTEGER)\n    SeqScan { table=t6 } | (t6.x:INTEGER, t6.y:INTEGER)\n```\n\n```\n# Query Plan Node Tree\n\nFilter: (t4.y = t5.y) AND (t4.x >= 1000000)) AND (t4.x < 1500000)) \n|\t\t\tAND (t6.x >= 100000)) AND (t6.x < 150000))\n│\n└── HashJoin: t5.y = t6.y\n    ├── HashJoin: t4.x = t5.x\n    │   ├── Sequential Scan: t4\n    │   └── Sequential Scan: t5\n    └── Sequential Scan: t6\n```\n画出plan node tree 可以看出，根据我之前的实现，predicate都飘在最上方，现在要做的是把predicate下推，其在后续优化函数的作用下可以与**NLJ、seq_scan**等node合并。\n\n在optimizer.h新增优化函数：\n```cpp\nauto OptimizePredicatePushdown(const AbstractPlanNodeRef &plan) -> AbstractPlanNodeRef;\n```\n同样在optimizer_custom_rules.cpp中实现：\n```cpp\nauto Optimizer::OptimizePredicatePushdown(const AbstractPlanNodeRef &plan) -> AbstractPlanNodeRef {\n  std::vector<AbstractPlanNodeRef> optimized_children{};\n  for (const auto &child : plan->children_) {\n    optimized_children.emplace_back(OptimizePredicatePushdown(child));\n  }\n  auto optimized_plan = plan->CloneWithChildren(std::move(optimized_children));\n\n  // Plan Should be a filter node.\n  if (optimized_plan->GetType() == PlanType::Filter) {\n    auto filter_plan = dynamic_cast<FilterPlanNode *>(optimized_plan.get());\n    std::vector<std::shared_ptr<ComparisonExpression>> pushdowns;\n    filter_plan->predicate_ = ParsePredicate(filter_plan->predicate_, filter_plan->OutputSchema(), pushdowns);\n    // No predicate could be pushed down, simply return.\n    if (pushdowns.empty()) {\n      return optimized_plan;\n    }\n    // All predicate could be pushed down, remove the filter node.\n    if (filter_plan->predicate_ == nullptr) {\n      return Pushdown(filter_plan->children_[0], pushdowns);\n    }\n    // Part of predicate could be pushed down.\n    return filter_plan->CloneWithChildren({Pushdown(filter_plan->children_[0], pushdowns)});\n  }\n\n  return optimized_plan;\n}\n```\n还有几个helper method我就不放出了，说一下思路：\n\n首先要获取predicate， 而predicate存在filter node中，所以当遇到一个filter node，用**ParsePredicate()** 来获取predicate。这个函数输入值**filter_plan->predicate_**是一个tree，递归遍历处理这个tree，将用**AND**连接的**ComparisonExpression**加入**pushdowns**这个vector，遇到OR则停止直接保持原样返回。加入pushdowns的expression要从原树中剔除。\n\n这样就获得了需要下推的predicates，将这些predicates和子节点放入下推函数**Pushdown()**。Pushdown中对遇到的各种类型的plan node分类处理，有的可以直接跳过，有的会阻塞下推，有的会使下推分叉(join node)。 类似：\n```cpp\nauto Optimizer::Pushdown(const AbstractPlanNodeRef &plan,\n                         std::vector<std::shared_ptr<ComparisonExpression>> &pushdowns) -> AbstractPlanNodeRef {\n  if (pushdowns.empty()) {\n    return plan;\n  }\n  // Check if plan is Filter.\n  switch (plan->GetType()) {\n    case PlanType::NestedLoopJoin: {\n      TODO: ... ... \n      return optimized_plan;\n    }\n\n    // Skip these nodes.\n    case PlanType::Filter:\n    case PlanType::Limit:\n    case PlanType::Sort: {\n      return plan->CloneWithChildren(std::vector<AbstractPlanNodeRef>{Pushdown(plan->GetChildAt(0), pushdowns)});\n    }\n\n    // Block pushdown, generate a filter plan above it.\n    case PlanType::SeqScan:\n    case PlanType::MockScan:\n    case PlanType::Aggregation:\n    case PlanType::Window:\n    case PlanType::Delete:\n    case PlanType::Update:\n    case PlanType::Insert:\n    case PlanType::Projection:\n    case PlanType::InitCheck: {\n      return std::make_shared<FilterPlanNode>(plan->output_schema_, ConcatencateComparisonAnd(pushdowns), plan);\n    }\n\n    // Advanced planNode, they should be generated latter.\n    case PlanType::TopNPerGroup:\n    case PlanType::TopN:\n    case PlanType::HashJoin:\n    case PlanType::NestedIndexJoin: {\n      UNREACHABLE(\"This kind of node should not appear in pushdown. They should be made after pushdown.\");\n    }\n\n    default: {\n      UNREACHABLE(\"Not supported planNode type.\");\n    }\n  }\n}\n\n```\n其中最复杂的就是遇到**NestedLoopJoin**，记得要修改像右子树继续下推的predicates的**col_idx**。\n\n当推到可以合并的节点，如seq_scan、NLJ的时候，只需要在其上方建一个filter node，因为后续其他的优化函数会帮你合并。而**OptimizePredicatePushdown**我是放在了**Optimizer::OptimizeCustom**中的靠前位置，这样可以先下推，再合并，优化调理清晰，充分利用已经写好的其他优化函数。\n\n实现下推后：\n```\n=== OPTIMIZER ===\nHashJoin { type=Inner, left_key=[\"#0.3\"], right_key=[\"#1.1\"] } \n| (t4.x:INTEGER, t4.y:INTEGER, t5.x:INTEGER, t5.y:INTEGER, t6.x:INTEGER, t6.y:INTEGER)\n\nHashJoin { type=Inner, left_key=[\"#0.0\"], right_key=[\"#1.0\"] } \n| (t4.x:INTEGER, t4.y:INTEGER, t5.x:INTEGER, t5.y:INTEGER)\n\nSeqScan { table=t4, filter=((#0.1<1500000)and(#0.1>=1000000)) } \n| (t4.x:INTEGER, t4.y:INTEGER)\n   \nSeqScan { table=t5 } | (t5.x:INTEGER, t5.y:INTEGER)\n    \nSeqScan { table=t6, filter=((#0.0<150000)and(#0.0>=100000)) }\n| (t6.x:INTEGER, t6.y:INTEGER)\n```\n```\nHashJoin: t4.y = t6.y\n| Output: (t4.x, t4.y, t5.x, t5.y, t6.x, t6.y)\n│\n├── HashJoin: t4.x = t5.x\n│   | Output: (t4.x, t4.y, t5.x, t5.y)\n│   │\n│   ├── SeqScan: table=t4\n│   │   | Filter: (t4.y >= 1000000) AND (t4.y < 1500000)\n│   │   | Output: (t4.x, t4.y)\n│   │\n│   └── SeqScan: table=t5\n│       | No Filter\n│       | Output: (t5.x, t5.y)\n│\n└── SeqScan: table=t6\n    | Filter: (t6.x >= 100000) AND (t6.x < 150000)\n    | Output: (t6.x, t6.y)\n```\n可看到谓词被下推到合适的地方了。\n\n此时leaderboard q2用时1900多，排名第八。\n\n## 进一步优化想法\n1. **Join重排 join reorder**。先估算表的大小，然后重排连接顺序，先join小表后join大表。\n2. **实现Hash join的比较左右表**。估算左右表大小，从而用小表构造hash map。\n3. **limit/agg 下推**。但leaderboard test中没有针对此的测试，所以实现了对排名提高无用。\n4. **query复用计算结果**。leaderboard测试逻辑貌似是把同一个query执行10次，所以实现储存query结果复用有可能可以大幅加速第2～10次query。\n\n# Query 3: The Mad Data Scientist\n一名购买了恒太房产的数据科学家意识到自己的所作所为之后，写下了这些奇怪的query：\n```sql\ncreate table t7(v int, v1 int, v2 int);\ncreate table t8(v4 int);\n\nexplain SELECT v, d1, d2 FROM (\n  SELECT v,\n         MAX(v1) AS d1, MIN(v1), MAX(v2), MIN(v2),\n         MAX(v1) + MIN(v1), MAX(v2) + MIN(v2),\n         MAX(v1) + MAX(v1) + MAX(v2) AS d2\n    FROM t7 LEFT JOIN (SELECT v4 FROM t8 WHERE 1 == 2) ON v < v4\n    GROUP BY v\n);\n```\n可以看到有很多奇怪的东西，比如始终等于false的\n```sql\nWHERE 1 == 2\n```\n还有计算了这些数据，但并没有输出：\n```sql\nMIN(v1), MAX(v2), MIN(v2),\nMAX(v1) + MIN(v1), MAX(v2) + MIN(v2),\n```\n第一个始终等于false的表达式考察的是优化器**常量折叠(constant folding)**能力，而第二个去除冗余的计算考察的是优化器列**剪枝(Column pruning)**的能力。\n\n先看看优化前：\n\n```\n=== OPTIMIZER ===\nProjection { exprs=[\"#0.0\", \"#0.1\", \"#0.7\"] } | (__subquery#0.t7.v:INTEGER, __subquery#0.d1:INTEGER, __subquery#0.d2:INTEGER)\n\n  Projection { exprs=[\"#0.0\", \"#0.1\", \"#0.2\", \"#0.3\", \"#0.4\", \"(#0.5+#0.6)\", \"(#0.7+#0.8)\", \"((#0.9+#0.10)+#0.11)\"] } | (__subquery#0.t7.v:INTEGER, __subquery#0.d1:INTEGER, __subquery#0.__item#2:INTEGER, __subquery#0.__item#3:INTEGER, __subquery#0.__item#4:INTEGER, __subquery#0.__item#5:INTEGER, __subquery#0.__item#6:INTEGER, __subquery#0.d2:INTEGER)\n  \n    Agg { types=[\"max\", \"min\", \"max\", \"min\", \"max\", \"min\", \"max\", \"min\", \"max\", \"max\", \"max\"], \n    aggregates=[\"#0.1\", \"#0.1\", \"#0.2\", \"#0.2\", \"#0.1\", \"#0.1\", \"#0.2\", \"#0.2\", \"#0.1\", \"#0.1\", \"#0.2\"], \n    group_by=[\"#0.0\"] }\n   \t| (t7.v:INTEGER, agg#0:INTEGER, agg#1:INTEGER, agg#2:INTEGER, agg#3:INTEGER, agg#4:INTEGER, agg#5:INTEGER, agg#6:INTEGER, agg#7:INTEGER, agg#8:INTEGER, agg#9:INTEGER, agg#10:INTEGER)\n    \n      Filter { predicate=(#0.0<#0.3) } | (t7.v:INTEGER, t7.v1:INTEGER, t7.v2:INTEGER, __subquery#1.t8.v4:INTEGER)\n      \n        HashJoin { type=Left, left_key=[], right_key=[] } | (t7.v:INTEGER, t7.v1:INTEGER, t7.v2:INTEGER, __subquery#1.t8.v4:INTEGER)\n        \n          SeqScan { table=t7 } | (t7.v:INTEGER, t7.v1:INTEGER, t7.v2:INTEGER)\n          \n          SeqScan { table=t8, filter=(1=2) } | (t8.v4:INTEGER)\n```\n```\nProjection: (__subquery#0.t7.v, __subquery#0.d1, __subquery#0.d2)\n│\n└── Projection: (__subquery#0.t7.v, __subquery#0.d1, __subquery#0.d2, derived columns)\n    │\n    └── Aggregation: Group by (t7.v), Aggregates: max/min\n        │\n        └── Filter: (t7.v < __subquery#1.t8.v4)\n            │\n            └── HashJoin: Left Join (t7, t8)\n                │\n                ├── Sequential Scan: t7\n                │\n                └── Sequential Scan: t8 (filtered: (1=2) )\n```\n\n\n## 常量折叠 Constant Folding\n常量折叠指的是优化器提前将可以计算的表达式计算出结果，否则每来一个tuple，表达式就要重新计算一次。\n\n在optimizer.h中增加declaration，并在optimizer_custom_rules.cpp中实现：\n```cpp\nauto Optimizer::OptimizeConstantFolding(const AbstractPlanNodeRef &plan) -> AbstractPlanNodeRef {\n  std::vector<AbstractPlanNodeRef> optimized_children{};\n  for (const auto &child : plan->children_) {\n    optimized_children.emplace_back(OptimizeConstantFolding(child));\n  }\n  auto optimized_plan = plan->CloneWithChildren(std::move(optimized_children));\n\n  // For filter, folding its predicate.\n  if (optimized_plan->GetType() == PlanType::Filter) {\n    auto filter_plan = dynamic_cast<FilterPlanNode *>(optimized_plan.get());\n    auto new_predicate = FoldingPredicate(filter_plan->predicate_);\n    // If the new_predicate is constant, \n    // true, return its child; false, return an empty value node.\n    if (auto new_predicate_const = dynamic_cast<const ConstantValueExpression *>(new_predicate.get())) {\n      if (new_predicate_const->Evaluate({}, Schema({})).GetAs<bool>()) {\n        return plan->children_[0];\n      }\n      return std::make_shared<ValuesPlanNode>(plan->output_schema_, std::vector<std::vector<AbstractExpressionRef>>{});\n    }\n    // new_predicate is not a constant, return a new filter.\n    return std::make_shared<FilterPlanNode>(filter_plan->output_schema_, new_predicate, filter_plan->children_[0]);\n  }\n  \n  return optimized_plan;\n}\n```\n\n实现常量折叠后：\n```\n# Query Execution Plan\n\nProjection: (output columns: #0.0, #0.1, #0.7)\n│\n└── Projection: (output columns: #0.0, #0.1, #0.2, #0.3, #0.4, (#0.5 + #0.6), (#0.7 + #0.8), ((#0.9 + #0.10) + #0.11))\n    │\n    └── Aggregation: Group By (#0.0), Aggregates (max/min on #0.1, #0.2)\n        │\n        └── Filter: (#0.0 < #0.3)\n            │\n            └── HashJoin: Left Join\n                │\n                ├── Sequential Scan: t7\n                │\n                └── Values: (empty set, rows=0)\n```\n可见seq_scan t8 被折叠成空的Value node了。此时可以对Join进行优化，如果右孩为空，直接返回左孩(left join)或直接返回false(inner join)。**但目前不可以直接删除Join，因为join之后schema会改变。**\n\n此时只折叠了filter里的expressions，这虽然已经足够应付测试，但你还可以将其余有expressions的plan都给折叠了，这就不贴出来了，留给读者实现。\n\n##  列剪枝 ColumnPruning\n可以看到实现常量折叠后的执行树中，\n```\nProjection: (output columns: #0.0, #0.1, #0.7)\n```\n最终结果只输出#0.0 #0.1 #0.7，但aggregate却计算了一长串：\n```\nProjection: (output columns: #0.0, #0.1, #0.2, #0.3, #0.4, (#0.5 + #0.6), (#0.7 + #0.8), ((#0.9 + #0.10) + #0.11)\n```\n所以当Projection的子节点为Projection或者Aggregation的时候，可以对子节点进行剪枝，避免不需要的计算和内存占用。注意，Column Pruning一定要自上而下，否则会导致pruning不完全。\n\n第二个projection应pruned为：\n```\nProjection: (output columns: #0.0, #0.1, #0.2, #0.3, #0.4, (#0.5 + #0.6), (#0.7 + #0.8), ((#0.9 + #0.10) + #0.11))\n\t\t\t\t\t\t\t｜\n\t\t\t\t\t\t\t｜\n\t\t\t\t\t\t\t\\/\nProjection: (output columns: #0.0, #0.1, ((#0.9 + #0.10) + #0.11))\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n```\n\n对于 Projection 结点, 分别处理子结点为 Projection 和 Aggregation 的情况.\n- 对于 Projection 结点, 用父节点对子结点修剪, 然后用子结点替换父节点.\n- 对于 Aggregation 结点, 用 Projection 中出现的列检查 Aggregation 中是否出现, 若没有则删除. 同时检查是否存在冗余, 若存在则删除.\n```cpp\nauto Optimizer::OptimizeColumnPruning(const AbstractPlanNodeRef &plan) -> AbstractPlanNodeRef {\n  std::shared_ptr<const AbstractPlanNode> optimized_plan = plan;\n\n  if (optimized_plan->GetType() == PlanType::Projection) {\n    auto projection_plan = dynamic_cast<const ProjectionPlanNode *>(optimized_plan.get());\n    auto child_plan = projection_plan->GetChildAt(0);\n\n    // Pruning when child is Projection.\n    if (child_plan->GetType() == PlanType::Projection) {\n      // Collect used cols.\n      std::vector<uint32_t> used_col_idxs;\n      used_col_idxs.reserve(optimized_plan->output_schema_->GetColumnCount());\n      for (const auto &expr : projection_plan->expressions_) {\n        CollectUsedColumnIdx(expr, used_col_idxs);\n      }\n      std::sort(used_col_idxs.begin(), used_col_idxs.end());\n      // Prune child.\n      auto child_projection_plan = dynamic_cast<const ProjectionPlanNode *>(child_plan.get());\n      std::vector<AbstractExpressionRef> pruned_exprs;\n      std::vector<Column> pruned_columns;\n      pruned_exprs.reserve(used_col_idxs.size());\n      pruned_columns.reserve(used_col_idxs.size());\n      for (uint32_t idx : used_col_idxs) {\n        pruned_exprs.push_back(child_projection_plan->expressions_[idx]);\n        pruned_columns.push_back(child_projection_plan->output_schema_->GetColumn(idx));\n      }\n      // Replace parent by its optimized child.\n      auto optimized_child_plan = std::make_shared<ProjectionPlanNode>(std::make_shared<Schema>(pruned_columns), \n          pruned_exprs, child_plan->children_[0]);\n      return OptimizeColumnPruning(optimized_child_plan);\n    }\n\n    // Pruning when child is Aggregation.\n    if (child_plan->GetType() == PlanType::Aggregation) {\n      // Collect used cols.\n      std::vector<uint32_t> used_col_idxs;\n      used_col_idxs.reserve(optimized_plan->output_schema_->GetColumnCount());\n      for (const auto &expr : projection_plan->expressions_) {\n        CollectUsedColumnIdx(expr, used_col_idxs);\n      }\n      std::sort(used_col_idxs.begin(), used_col_idxs.end());\n      // Prune child.\n      auto child_aggregation_plan = dynamic_cast<const AggregationPlanNode *>(child_plan.get());\n      size_t group_col_length = child_aggregation_plan->group_bys_.size();\n      std::vector<AbstractExpressionRef> pruned_aggregates;\n      std::vector<AggregationType> pruned_agg_types;\n      std::vector<Column> pruned_columns;\n      pruned_aggregates.reserve(used_col_idxs.size());\n      pruned_agg_types.reserve(used_col_idxs.size());\n      pruned_columns.reserve(used_col_idxs.size());\n      for (size_t i = 0; i < group_col_length; ++i) {\n        pruned_columns.push_back(child_aggregation_plan->output_schema_->GetColumn(i));\n      }\n      for (uint32_t idx : used_col_idxs) { // Maybe optimized to binary, upper_bound.\n        if (idx >= group_col_length) {\n          pruned_aggregates.push_back(child_aggregation_plan->aggregates_[idx - group_col_length]);\n          pruned_agg_types.push_back(child_aggregation_plan->agg_types_[idx - group_col_length]);\n          pruned_columns.push_back(child_aggregation_plan->output_schema_->GetColumn(idx));\n        }\n      }\n      // Make new optimized node child.\n      auto optimized_aggr = std::make_shared<AggregationPlanNode>(\n          std::make_shared<Schema>(pruned_columns), child_aggregation_plan->children_[0], \n          child_aggregation_plan->group_bys_, pruned_aggregates, pruned_agg_types);\n      // Modified parent node schema and expr.\n      std::vector<AbstractExpressionRef> pruned_exprs;\n      pruned_exprs.reserve(used_col_idxs.size());\n      for (const auto &expr : projection_plan->expressions_) {\n        pruned_exprs.push_back(PrunedProjectionExpression(expr, used_col_idxs));\n      }\n      optimized_plan = std::make_shared<ProjectionPlanNode>(projection_plan->output_schema_, pruned_exprs, optimized_aggr);\n      return optimized_plan->CloneWithChildren({OptimizeColumnPruning(optimized_plan->children_[0])});\n    }\n  }\n\n  if (optimized_plan->GetType() == PlanType::SeqScan || optimized_plan->GetType() == PlanType::MockScan ||\n      optimized_plan->GetType() == PlanType::IndexScan) {\n    return optimized_plan;\n  }\n\n  std::vector<AbstractPlanNodeRef> new_children{};\n  for (const auto &child : plan->children_) {\n    new_children.emplace_back(OptimizeColumnPruning(child));\n  }\n  return plan->CloneWithChildren(std::move(new_children));\n}\n```\n到了这里，我也发现了我OptimizeNLJAsHashJoin()的一个bug，要在OptimizeNLJAsHashJoin()中需要加一行：**当尝试在Join Node上方生成新的filter Node时候，如join类型不是Inner Join, 要保持NLJ而不能优化成Hash_Join**。\n\n我实现OptimizeNLJAsHashJoin()的时候会尝试多生成一个filter Node，但是如果是Left Join 的话，Join后的tuple中有可能出现null value，而新的filer有可能会导致这些包含null value的tuple全被去除掉。所以在Left Join的时候，要保持去除的判断语句在Join Node内部，而不能剥离开。所以其实gradescope上给的基础测试非常不全面，即使通过所以测试，代码也可能有很多很大的bug。\n\ndebug并优化后：\n```\nProjection { exprs=[\"#0.0\", \"#0.1\", \"((#0.2+#0.3)+#0.4)\"] }\n\n  Agg { types=[\"max\", \"max\", \"max\", \"max\"]\n  ,aggregates=[\"#0.1\", \"#0.1\", \"#0.1\", \"#0.2\"]\n  ,group_by=[\"#0.0\"] }\n  \n    NestedLoopJoin { type=Left, predicate=(#0.0<#1.0) }\n    \n      MockScan { table=__mock_t7 }\n      \n      Values { rows=0 }\n```\n此时已经可以较快地通过q3了，但你会发现，aggr中居然还有重复的计算:\n```\n types=     [\"max\",  \"max\",  \"max\",  \"max\"],\n aggregates=[\"#0.1\", \"#0.1\", \"#0.1\", \"#0.2\"]\n```\n对齐一下，显然对#0.1的max居然计算了三遍...所以可以进一步对aggregation去重。\n\n```cpp\nvoid Optimizer::CollectUsedColumnIdx(const AbstractExpressionRef &expr, std::vector<uint32_t> &col_idxs) {\n  if (const auto *arith_expr = dynamic_cast<const ArithmeticExpression*>(expr.get())) {\n    CollectUsedColumnIdx(expr->children_[0], col_idxs);\n    CollectUsedColumnIdx(expr->children_[1], col_idxs);\n    return;\n  }\n  if (const auto *column_value_expr = dynamic_cast<const ColumnValueExpression *>(expr.get())) {\n    if (std::find(col_idxs.begin(), col_idxs.end(), column_value_expr->GetColIdx()) == col_idxs.end()) {\n      col_idxs.push_back(column_value_expr->GetColIdx());\n    }\n    return;\n  }\n  if (dynamic_cast<const ConstantValueExpression *>(expr.get())) {\n    return;\n  }\n  std::string message = \"Projection expressions should only contain arithmetic, column and constant: \";\n  UNREACHABLE(message);\n}\n\nauto Optimizer::PrunedProjectionExpression(const AbstractExpressionRef &expr, std::vector<int> idx_map) \n    -> AbstractExpressionRef {\n  // Notice: used_col_idxs is sorted.\n  if (const auto *arith_expr = dynamic_cast<const ArithmeticExpression *>(expr.get())) {\n    return expr->CloneWithChildren({PrunedProjectionExpression(expr->children_[0], idx_map),\n                                    PrunedProjectionExpression(expr->children_[1], idx_map)});\n  }\n  if (const auto *column_value_expr = dynamic_cast<const ColumnValueExpression *>(expr.get())) {\n    int new_col_idx = idx_map[column_value_expr->GetColIdx()];\n    return std::make_shared<ColumnValueExpression>(column_value_expr->GetTupleIdx(), new_col_idx, \n        column_value_expr->GetReturnType());\n  }\n  return expr;\n}\n\nauto Optimizer::OptimizeColumnPruning(const AbstractPlanNodeRef &plan) -> AbstractPlanNodeRef {\n  std::shared_ptr<const AbstractPlanNode> optimized_plan = plan;\n\n  if (optimized_plan->GetType() == PlanType::Projection) {\n    auto projection_plan = dynamic_cast<const ProjectionPlanNode *>(optimized_plan.get());\n    auto child_plan = projection_plan->GetChildAt(0);\n\n    // Pruning when child is Projection.\n    if (child_plan->GetType() == PlanType::Projection) {\n      // Collect used cols.\n      std::vector<uint32_t> used_col_idxs;\n      used_col_idxs.reserve(optimized_plan->output_schema_->GetColumnCount());\n      for (const auto &expr : projection_plan->expressions_) {\n        CollectUsedColumnIdx(expr, used_col_idxs);\n      }\n      std::sort(used_col_idxs.begin(), used_col_idxs.end());\n      // Prune child.\n      auto child_projection_plan = dynamic_cast<const ProjectionPlanNode *>(child_plan.get());\n      std::vector<AbstractExpressionRef> pruned_exprs;\n      std::vector<Column> pruned_columns;\n      pruned_exprs.reserve(used_col_idxs.size());\n      pruned_columns.reserve(used_col_idxs.size());\n      for (uint32_t idx : used_col_idxs) {\n        pruned_exprs.push_back(child_projection_plan->expressions_[idx]);\n        pruned_columns.push_back(child_projection_plan->output_schema_->GetColumn(idx));\n      }\n      // Replace parent by its optimized child.\n      auto optimized_child_plan = std::make_shared<ProjectionPlanNode>(std::make_shared<Schema>(pruned_columns), \n          pruned_exprs, child_plan->children_[0]);\n      return OptimizeColumnPruning(optimized_child_plan);\n    }\n\n    // Pruning when child is Aggregation.\n    if (child_plan->GetType() == PlanType::Aggregation) {\n      auto child_aggregation_plan = dynamic_cast<const AggregationPlanNode *>(child_plan.get());\n\n      // Collect used cols.\n      std::vector<uint32_t> used_col_idxs;\n      used_col_idxs.reserve(optimized_plan->output_schema_->GetColumnCount());\n      size_t group_cols = child_aggregation_plan->GetGroupBys().size();\n      for (size_t i = 0; i < group_cols; ++i) {\n        // Must use group by columns.\n        used_col_idxs.push_back(i);\n      }\n      for (const auto &expr : projection_plan->expressions_) {\n        CollectUsedColumnIdx(expr, used_col_idxs);\n      }\n      std::sort(used_col_idxs.begin(), used_col_idxs.end());\n\n      // Prune child.\n      size_t group_col_length = child_aggregation_plan->group_bys_.size();\n      std::vector<AbstractExpressionRef> pruned_aggregates;\n      std::vector<AggregationType> pruned_agg_types;\n      std::vector<Column> pruned_columns;\n      // For aggr deduplication, [expression.toString + AggregationType]\n      std::unordered_map<std::string, uint32_t> exist_expr;\n      std::unordered_map<uint32_t, uint32_t> re_direct;\n\n      pruned_aggregates.reserve(used_col_idxs.size());\n      pruned_agg_types.reserve(used_col_idxs.size());\n      pruned_columns.reserve(used_col_idxs.size());\n\n      for (size_t i = 0; i < group_col_length; ++i) {\n        pruned_columns.push_back(child_aggregation_plan->output_schema_->GetColumn(i));\n      }\n      for (uint32_t idx : used_col_idxs) { // Maybe optimized to binary, upper_bound.\n        if (idx >= group_col_length) {  // idx >= group_col_length means it's aggr.\n          auto aggr_expr = child_aggregation_plan->aggregates_[idx - group_col_length];\n          auto aggr_type = child_aggregation_plan->agg_types_[idx - group_col_length];\n          std::string aggr_pair = aggr_expr->ToString() + std::to_string(static_cast<int>(aggr_type));\n          if (exist_expr.count(aggr_pair) == 0) {\n            // Not exist yet, add to pruned lists.\n            pruned_aggregates.push_back(aggr_expr);\n            pruned_agg_types.push_back(aggr_type);\n            pruned_columns.push_back(child_aggregation_plan->output_schema_->GetColumn(idx));\n            exist_expr[aggr_pair] = pruned_columns.size() - 1;\n          } else {\n            // Has existed, add to re_direct map.\n            re_direct[idx] = exist_expr.find(aggr_pair)->second;\n          }\n        }\n      }\n\n      // Make new optimized node child.\n      auto optimized_aggr = std::make_shared<AggregationPlanNode>(\n          std::make_shared<Schema>(pruned_columns), child_aggregation_plan->children_[0], \n          child_aggregation_plan->group_bys_, pruned_aggregates, pruned_agg_types);\n\n      // Modified parent node schema and expr.\n      std::vector<AbstractExpressionRef> pruned_exprs;\n      pruned_exprs.reserve(used_col_idxs.size());\n      std::vector<int> idx_map = RearrangeColIdxs(re_direct, used_col_idxs);\n\n      for (const auto &expr : projection_plan->expressions_) {\n        pruned_exprs.push_back(PrunedProjectionExpression(expr, idx_map));\n      }\n      optimized_plan = std::make_shared<ProjectionPlanNode>(projection_plan->output_schema_, pruned_exprs, optimized_aggr);\n      return optimized_plan->CloneWithChildren({OptimizeColumnPruning(optimized_plan->children_[0])});\n    }\n  }\n\n  if (optimized_plan->GetType() == PlanType::SeqScan || optimized_plan->GetType() == PlanType::MockScan ||\n      optimized_plan->GetType() == PlanType::IndexScan) {\n    return optimized_plan;\n  }\n\n  std::vector<AbstractPlanNodeRef> new_children{};\n  for (const auto &child : plan->children_) {\n    new_children.emplace_back(OptimizeColumnPruning(child));\n  }\n  return plan->CloneWithChildren(std::move(new_children));\n}\n\nauto Optimizer::RearrangeColIdxs(std::unordered_map<uint32_t, uint32_t> &re_direct, std::vector<uint32_t> &used_col_idxs) \n    -> std::vector<int> {\n  // Initialize the result map and the del array\n  int max_col_idx = static_cast<int>(used_col_idxs.back());\n  std::vector<int> col_idx_map(max_col_idx + 1, -1);\n  std::vector<int> del(max_col_idx + 2, 0);\n\n  // Cache the result of std::lower_bound for each i\n  std::vector<uint32_t> idx_map(max_col_idx + 1, used_col_idxs.size());\n  for (int i = 0; i <= max_col_idx; ++i) {\n    idx_map[i] = std::find(used_col_idxs.begin(), used_col_idxs.end(), i) - used_col_idxs.begin();\n  }\n\n  // First pass: Fill col_idx_map and update del\n  for (int i = 0; i <= max_col_idx; ++i) { // 11\n    uint32_t idx = idx_map[i];\n    if (idx < used_col_idxs.size()) {\n      if (re_direct.count(i)) {\n        col_idx_map[i] = re_direct[i];\n        del[idx + 1] -= 1;\n      } else {\n        // When it's not in re_direct.\n        col_idx_map[i] = idx;\n      }\n    }\n  }\n\n  // Compute cumulative del values\n  for (size_t i = 1; i < del.size(); ++i) {\n    del[i] += del[i - 1];\n  }\n\n  // Final adjustment for col_idx_map\n  for (int i = 0; i <= max_col_idx; ++i) {\n    uint32_t idx = idx_map[i];\n    if (col_idx_map[i] != -1 && !re_direct.count(idx)) {\n      col_idx_map[i] += del[col_idx_map[i]];\n    }\n  }\n\n  /*\n    printf(\"re_direct:\");\n    printUnorderedMap(re_direct);\n    printf(\"idx_map:\");\n    printVector(idx_map);\n    printf(\"del:\");\n    printVector(del);\n    printf(\"used_col_idxs:\");\n    printVector(used_col_idxs);\n    printf(\"col_idx_map:\");\n    printVector(col_idx_map);\n  */\n\n  return col_idx_map;\n}\n```\n\n优化后：\n\n```\nProjection { exprs=[\"#0.0\", \"#0.1\", \"((#0.1+#0.1)+#0.2)\"] } \n| (__subquery#0.t7.v:INTEGER, __subquery#0.d1:INTEGER, __subquery#0.d2:INTEGER)\n\n  Agg { types=[\"max\", \"max\"], aggregates=[\"#0.1\", \"#0.2\"], group_by=[\"#0.0\"] } \n  | (t7.v:INTEGER, agg#0:INTEGER, agg#10:INTEGER)\n  \n    NestedLoopJoin { type=Left, predicate=(#0.0<#1.0) } \n    | (t7.v:INTEGER, t7.v1:INTEGER, t7.v2:INTEGER, __subquery#1.t8.v4:INTEGER)\n    \n      SeqScan { table=t7 } | (t7.v:INTEGER, t7.v1:INTEGER, t7.v2:INTEGER)\n      \n      Values { rows=0 } | (__subquery#1.t8.v4:INTEGER)\n```\n可见aggr只计算了两个max。\n\n现在q3用时可以达到700多，并且其他测试也都可以通过。\n\n# 后记\n由于给的基础测试太不全面了，导致我自己又写了一点，但仍然不全面。所以**实际上我的代码肯定还有bug**，只是还没找到且不影响线上测试。想用线上测试就必须要遵循一些代码格式，比如不能新增文件，某些函数只能写在特定文件，大部分初始代码不能自己修改...这些东西很大地限制了发挥，真诚希望以后能改进一下，给我们更多自由度，至少能新增文件吧。。。\n\n目前三个leaderboard test总分排名进了前十，而事实上23fall也没有多少人真正完成了project 3 的全部leaderboard部分。所谓的cmu15445烂大街，其实确实是个谎言。事实上23fall的project 3 leaderboard做完的只有不到20个人，更别说project 4了。\n\n**我认为project 3是最重要的一个project**。做过前两个project的都知道，project 1、2 和数据库结构真没啥太大关系。所以当我做完1、2的时候，对数据库具体结构是几乎没有进一步了解。而project 3 才是真正深入Bustub执行过程，我做完3后才对数据库各个组件有了一个真正直观的认识。非常推荐自己认真完成这个project。\n\n贴出来的代码跟一坨答辩一样，后续我对代码进行了一些重构，但现在真是累死了，写不动了。但话说起来，这一坨也让读者阅读起来更困难，也算间接保护了课程无法被抄袭。。。\n\n","tags":["数据库","Bustub"],"categories":["数据库"]},{"title":"Hello World","url":"/2024/12/07/hello-world/","content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n"}]